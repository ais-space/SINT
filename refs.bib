@misc{agentgpt,
  author = {Reworkd},
  title = {AgentGPT: Deploy Autonomous AI Agents in your browser},
  year = {2023},
  howpublished = {\url{https://github.com/reworkd/AgentGPT}},
  note = {GitHub repository}
}

@misc{hyperwrite2025,
  author = {HyperWrite},
  title = {AI Debate Assistant},
  year = {2025},
  howpublished = {\url{https://hyperwriteai.com/aitools/debate-assistant}}
}

@misc{langchain2023,
  author = {Chase, H.},
  title = {LangChain: A Framework for Developing Applications Powered by Language Models},
  year = {2023},
  howpublished = {\url{https://github.com/langchain-ai/langchain}},
  note = {GitHub repository}
}

@misc{vdebater2023,
  author = {Hayden, W.},
  title = {Virtual Debater AI Simulator},
  year = {2023},
  howpublished = {\url{https://github.com/haydenw-uk/vDebaterAI}},
  note = {GitHub repository}
}

@article{deevo2025,
  author = {Amazon Science},
  title = {Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and ELO Ratings},
  journal = {arXiv preprint arXiv:2506.00178v2 [cs.AI]},
  year = {2025},
  doi = {10.48550/arXiv.2506.00178},
  url = {https://doi.org/10.48550/arXiv.2506.00178}
}

@article{sun2025inot,
  author = {Sun, H. and Zeng, S.},
  title = {Introspection of Thought Helps AI Agents},
  journal = {arXiv preprint arXiv:2507.08664v1 [cs.AI]},
  year = {2025},
  doi = {10.48550/arXiv.2507.08664},
  url = {https://doi.org/10.48550/arXiv.2507.08664}
}

@article{multi2024,
  author = {Li, Z. and others},
  title = {Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models},
  journal = {arXiv preprint arXiv:2411.00492 [cs.AI]},
  year = {2024},
  doi = {10.48550/arXiv.2411.00492},
  url = {https://doi.org/10.48550/arXiv.2411.00492}
}

@article{wei2022cot,
  author = {Wei, J. and others},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  journal = {arXiv preprint arXiv:2201.11903v6 [cs.CL]},
  year = {2022},
  doi = {10.48550/arXiv.2201.11903},
  url = {https://doi.org/10.48550/arXiv.2201.11903}
}

@article{yao2023react,
  author = {Yao, S. and others},
  title = {ReAct: Synergizing Reasoning and Acting in Language Models},
  journal = {arXiv preprint arXiv:2210.03629v3 [cs.CL]},
  year = {2023},
  doi = {10.48550/arXiv.2210.03629},
  url = {https://doi.org/10.48550/arXiv.2210.03629}
}

@article{vibecoding2025,
  author = {Ge, Y. and others},
  title = {A Survey of Vibe Coding with Large Language Models},
  journal = {arXiv preprint arXiv:2510.12399v1 [cs.AI]},
  year = {2025},  
  doi = {10.48550/arXiv.2510.12399},
  url = {https://doi.org/10.48550/arXiv.2510.12399}
}

@article{yao2023tot,
  author = {Yao, S. and others},
  title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  journal = {arXiv preprint arXiv:2305.10601v2 [cs.CL]},
  year = {2023},
  doi = {10.48550/arXiv.2305.10601},
  url = {https://doi.org/10.48550/arXiv.2305.10601}
}

@article{zhang2025verbalized,
  title         = {Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity},
  author        = {Jiayi Zhang and others},
  year          = {2025},
  archivePrefix = {arXiv},
  eprint        = {2510.01171},
  primaryClass  = {cs.CL},
  doi           = {10.48550/arXiv.2510.01171},
  url           = {https://arxiv.org/abs/2510.01171},
}
